# Hugging Face API Migration

## What Changed

The application has been updated to use **Hugging Face's Inference API** instead of running models locally. This eliminates the need for large model downloads and heavy dependencies.

## Benefits

‚úÖ **No local storage required** - Models run in the cloud  
‚úÖ **No PyTorch/Transformers dependencies** - Lighter installation  
‚úÖ **No memory issues** - No local GPU/CPU model loading  
‚úÖ **Always up-to-date models** - Latest model versions automatically  
‚úÖ **Free tier available** - Many models have free usage limits  

## New Requirements

Install the lightweight requirements:
```bash
pip install -r requirements_rag_vision_api.txt
```

## Setup

1. **Get a free Hugging Face API key:**
   - Go to https://huggingface.co/settings/tokens
   - Create a new token (free)
   - Copy the token

2. **Configure in Streamlit:**
   - Run the app: `streamlit run shifter_rag_app_vision.py`
   - Add your API key in the sidebar under "ü§ó HuggingFace API"
   - Test the connection

## Available Models

The following models are available via API:

- **BLIP-2 OPT 2.7B** (Fast) - Free tier
- **BLIP-2 Flan T5 XL** (High Quality) - Free tier  
- **LLaVA 1.5 7B** (Vision-Language) - Paid tier
- **GIT Base** (Microsoft) - Free tier
- **ViT-GPT2** (Lightweight) - Free tier

## Usage

1. Upload documents as before
2. Upload images in the "üëÅÔ∏è Vision Analysis" tab
3. Ask questions about the images
4. The AI will analyze using the selected Hugging Face model

## Troubleshooting

- **"API Key Required"**: Add your Hugging Face API key in the sidebar
- **"Rate Limit Exceeded"**: Wait a moment or upgrade to paid tier
- **"Model Loading"**: Some models take time to load on first use
- **Connection issues**: Check your internet connection

## Cost

- **Free tier**: Many models available with rate limits
- **Paid tier**: Higher rate limits and access to premium models
- **No local storage costs**: Everything runs in the cloud
